# Backend Configuration
GRPC_PORT=50051
HOST=127.0.0.1

# Model Paths (relative to backend directory)
LLAMA_MODEL_PATH=models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

# Whisper model (use 'medium' for better quality)
WHISPER_MODEL_PATH=medium
WHISPER_MODEL_SIZE=medium

# Vision model (only if NOT using Llama 3.2 Vision)
VISION_MODEL_PATH=Salesforce/blip2-opt-2.7b

# Application Settings
MAX_VIDEO_SIZE_MB=100
MAX_VIDEO_DURATION_SEC=120
CHAT_HISTORY_DB=data/chat_history.db

# Performance Settings (M2 optimized)
N_GPU_LAYERS=1  # For Metal acceleration
N_THREADS=8     # M2 has 8 cores (4 performance + 4 efficiency)
N_CTX=4096      # Context window (Llama 3.x supports up to 128K but 4K is good balance)
