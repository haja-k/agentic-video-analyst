# Agentic Video Analyst

> **Local AI-powered video analysis with multi-agent orchestration**

**Status:** Phase 5 Complete - gRPC Service Live | Ready for Frontend Integration  
**Platform:** MacBook Air M2, 16GB RAM | **Updated:** Jan 9, 2026  
**Purpose:** Intel Senior GenAI Software Solutions Engineer Application

---

## ğŸ¯ Overview

**Agentic Video Analyst** is a fully local AI desktop application that uses multi-agent orchestration to analyze short videos (~1 min) through natural language queries. All AI inference runs offline with no cloud dependencies.

**Key Capabilities:**
- **Intelligent Orchestration:** Llama 3.1 8B routes queries to specialized agents
- **Speech-to-text:** Whisper-powered transcription with timestamps
- **Visual Intelligence:** Object detection, scene description, OCR, graph analysis
- **Natural Language Interface:** Chat-based video querying
- **Report Generation:** Automated PDF/PPT creation from analysis
- **Fully Local:** No internet required, all inference on-device

**Current Status:**
- âœ… All agents implemented and tested
- âœ… Orchestrator routing queries via MCP protocol
- âœ… Multi-agent coordination through MCP servers
- âœ… gRPC service with 5 endpoints fully functional
- âœ… PDF/PPTX report generation with session context
- âœ… Backend codebase reorganized and cleaned
- âœ… Full backend test suite verified
- â³ Frontend UI in development (Phase 6)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         gRPC          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React +   â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Python Backend     â”‚
â”‚   Tauri     â”‚   Streaming RPC      â”‚                      â”‚
â”‚  (Desktop)  â”‚                       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚  â”‚ Orchestrator   â”‚  â”‚
                                      â”‚  â”‚ (Llama 3.1 8B) â”‚  â”‚
                                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                      â”‚           â”‚          â”‚
                                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                      â”‚  â†“        â†“        â†“ â”‚
                                      â”‚ Trans   Vision   Gen â”‚
                                      â”‚ Agent   Agent  Agent â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚   AI Models     â”‚
                                      â”‚  (Local/Metal)  â”‚
                                      â”‚                 â”‚
                                      â”‚ â€¢ Llama 3.1 8B  â”‚
                                      â”‚ â€¢ Whisper       â”‚
                                      â”‚ â€¢ BLIP-2+YOLOv8 â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components
- **Frontend:** React + Tauri (desktop app) - In Development
- **Backend:** Python with multi-agent orchestration
- **gRPC Service:** 5 endpoints (UploadVideo, QueryVideo, StreamQuery, GetChatHistory, GenerateReport)
- **Orchestrator:** Llama 3.1 8B for query understanding and routing via MCP
- **MCP Layer:** Protocol servers wrapping each specialized agent
- **Agents:** Transcription (Whisper), Vision (BLIP-2+YOLOv8), Generation (PDF/PPT)
- **MCP Protocol:** Standardized tool interface for agent coordination
- **AI Runtime:** llama.cpp with Metal acceleration
- **Session Management:** Context-aware report generation with stored results

---

## ğŸ¬ Testing

### Test gRPC Service (Full Integration)
```bash
cd backend
source venv/bin/activate

# Start gRPC server (runs in background)
./run.sh

# Run comprehensive test suite
python tests/test_grpc_client.py uploads/CunkOnEarth.mp4
```

**Tests all endpoints:**
- âœ… Video upload with metadata extraction
- âœ… Transcription queries via orchestrator
- âœ… Vision analysis (objects + scene descriptions)
- âœ… Streaming query responses
- âœ… Chat history persistence
- âœ… PDF report generation with session context

### Test Orchestrator (Query Routing & Multi-Agent Coordination)
```bash
cd backend/tests
source ../venv/bin/activate

# Test intent analysis only (quick test)
python test_orchestrator.py --intent-only

# Full orchestrator test with video
python test_orchestrator.py ../uploads/your_video.mp4
```

The orchestrator uses Llama 3.1 8B to understand queries and route to appropriate agents.

**Example queries tested:**
- "Transcribe the video"
- "What objects can you see?"
- "Are there any graphs or charts?"
- "Create a PowerPoint with key points"
- "Summarize our discussion"

### Test Transcription Agent
```bash
cd backend/tests
source ../venv/bin/activate
python test_transcription.py ../uploads/your_video.mp4
```

Outputs full transcription with timestamps to `results/transcription_result.json`

### Test Vision Agent
```bash
cd backend/tests
source ../venv/bin/activate
python test_vision.py ../uploads/your_video.mp4
```

Outputs scene descriptions and detected objects to `results/vision_result.json`

### Test Generation Agent
```bash
cd backend/tests
source ../venv/bin/activate
python test_generation.py
```

Generates `results/video_report.pdf` and `results/video_presentation.pptx` from previous results

---

## ğŸ“ Project Structure

```
agentic-video-analyst/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ venv/              # Virtual env (50+ packages) âœ…
â”‚   â”œâ”€â”€ models/            # AI models (Llama 3.1 8B, YOLOv8) âœ…
â”‚   â”œâ”€â”€ agents/            # AI agents âœ…
â”‚   â”‚   â”œâ”€â”€ orchestrator_agent.py    # Query routing with Llama 3.1 8B
â”‚   â”‚   â”œâ”€â”€ transcription_agent.py   # Whisper integration
â”‚   â”‚   â”œâ”€â”€ vision_agent.py          # BLIP-2 + YOLOv8
â”‚   â”‚   â””â”€â”€ generation_agent.py      # PDF/PPT creation
â”‚   â”œâ”€â”€ mcp_servers/       # MCP protocol implementations âœ…
â”‚   â”œâ”€â”€ generated/         # Generated proto files âœ…
â”‚   â”œâ”€â”€ logs/              # Server logs (gitignored) âœ…
â”‚   â”œâ”€â”€ uploads/           # Video upload directory âœ…
â”‚   â”œâ”€â”€ tests/             # Agent test scripts âœ…
â”‚   â”‚   â”œâ”€â”€ test_orchestrator.py     # Orchestrator tests
â”‚   â”‚   â”œâ”€â”€ test_all.sh              # Run all tests
â”‚   â”‚   â”œâ”€â”€ test_grpc_client.py      # Full gRPC integration test
â”‚   â”‚   â””â”€â”€ results/                 # Test outputs (PDFs, JSONs)
â”‚   â”œâ”€â”€ run.sh             # Start backend server âœ…
â”‚   â”œâ”€â”€ status.sh          # Check server status âœ…
â”‚   â””â”€â”€ main.py            # Backend entry point âœ…
â”œâ”€â”€ frontend/              # React + Tauri app (TODO)
â”œâ”€â”€ proto/                 # gRPC definitions âœ…
â”œâ”€â”€ docs/                  # Documentation âœ…
â””â”€â”€ README.md              # This file
```

---

## âœ… What's Already Setup

- [x] Python 3.12 virtual environment with 50+ packages
- [x] llama-cpp-python with Metal acceleration (M2 GPU)
- [x] openai-whisper for speech-to-text
- [x] PyTorch 2.8.0 with MPS (Metal) support
- [x] Transformers, OpenCV, moviepy, ReportLab, python-pptx
- [x] System dependencies (ffmpeg 8.0.1, pkg-config)
- [x] **Orchestrator Agent** - Llama 3.1 8B query routing via MCP
- [x] **Transcription Agent** - Whisper integration complete
- [x] **Vision Agent** - BLIP-2 + YOLOv8 working
- [x] **Generation Agent** - PDF/PPT creation with Calibri 15pt
- [x] MCP server implementations (transcription, vision, generation)
- [x] MCP routing complete - orchestrator communicates via MCP protocol
- [x] Multi-agent coordination and context management
- [x] Comprehensive test suite with all agents
- [x] gRPC protocol definitions

---

## ğŸš€ Quick Start

### 1. Download AI Model (~5 mins)

**Recommended: Llama 3.1 8B** (publicly available, no auth needed)

```bash
cd backend/models
curl -L "https://huggingface.co/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf" \
     -o Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf \
     --progress-bar

# Verify (should show ~4.9GB)
ls -lh *.gguf
```

**Why Llama 3.1 8B?**
- âœ… Public (no HuggingFace auth)
- âœ… Strong instruction following
- âœ… Fits in 16GB RAM (~5-6GB usage)
- âœ… Fast on M2 with Metal

### 2. Configure Environment

```bash
cd backend
cp .env.example .env
```

Edit `backend/.env`:
```env
LLAMA_MODEL_PATH=models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
WHISPER_MODEL_SIZE=medium
BACKEND_HOST=0.0.0.0
BACKEND_PORT=50051
```

### 3. Test Setup

```bash
cd backend
source venv/bin/activate
python test_models.py
```

Expected: All components âœ… Ready

### 4. Compile gRPC Protocols

```bash
cd backend
source venv/bin/activate
python -m grpc_tools.protoc -I../proto --python_out=. --grpc_python_out=. ../proto/video_analysis.proto
```

### 5. Start Backend (Development)

```bash
cd backend
source venv/bin/activate
python main.py
```

---

## ğŸ“‹ Development Status

### Phase 1: Foundation âœ… COMPLETE
- Environment setup with 50+ packages
- Metal GPU acceleration configured
- All system dependencies installed

### Phase 2: Agent Implementation âœ… COMPLETE
- [x] **TranscriptionAgent** - Whisper integration complete
- [x] **VisionAgent** - BLIP-2 + YOLOv8 integration complete
- [x] **GenerationAgent** - PDF/PPT creation complete
- [x] **OrchestratorAgent** - Llama 3.1 8B query routing complete
- [x] MCP server implementations
- [x] Main backend server with all agents

### Phase 3: Integration âœ… COMPLETE
- [x] Orchestrator routes queries via MCP protocol layer
- [x] MCP servers wrap all specialized agents
- [x] Multi-agent coordination through MCP working
- [x] Context management across agents
- [x] gRPC service definitions and implementation
- [x] Full backend test suite verified
- [x] Backend codebase reorganized (generated/, logs/, models/)
- [ ] Frontend React + Tauri UI
- [ ] Persistent chat storage (SQLite)

### Phase 4: Frontend Development ğŸ”„ IN PROGRESS
- [ ] React UI with gRPC-web client
- [ ] Video upload and query interface
- [ ] Streaming chat responses
- [ ] Report download functionality
- [ ] Desktop app packaging (Tauri)

### Phase 5: Polish & Deployment ğŸ“… PLANNED
- [ ] End-to-end testing with frontend
- [ ] Performance optimization
- [ ] Demo scenarios and user guide
- [ ] Final packaging and deployment

---

## ğŸ¬ Demo Scenarios

1. **Transcription:** Upload video â†’ Extract audio transcript
2. **Vision:** "What objects are in this video?"
3. **Analysis:** "Are there any graphs? Describe them."
4. **Generation:** Generate summary report (PDF/PPT)

---

## ğŸ”§ Technical Highlights

### Metal Acceleration (M2)
- llama-cpp-python: `-DLLAMA_METAL=on`
- PyTorch: MPS backend enabled
- ~2-3x faster inference vs CPU

### Agentic Architecture
- Model Context Protocol (MCP) for standardized agent communication
- Each agent wrapped by MCP server with tool registration
- Orchestrator routes through MCP protocol layer (satisfies assignment requirement)
- Main orchestrator uses Llama 3.1 8B for intent understanding

### Local-First Design
- All models run in RAM
- No internet required after setup
- Suitable for confidential content

---

## ğŸ“Š Resource Usage (16GB M2)

| Component | RAM Usage |
|-----------|-----------|
| Llama 3.1 8B | ~5-6GB |
| Whisper Medium | ~1.5GB |
| PyTorch/Vision | ~1-2GB |
| System/Other | ~2GB |
| **Total** | **~10-11GB / 16GB** |

Comfortable headroom for development tools.

---

## ğŸ› Known Issues & Solutions

1. **Llama 3.2 Vision 11B not available**  
   â†’ Use Llama 3.1 8B (publicly available)

2. **faster-whisper build errors**  
   â†’ Using openai-whisper (stable alternative)

3. **MCP SDK requires Python 3.10+**  
   â†’ Custom MCP implementation (in `backend/mcp_servers/`)

4. **Model download authentication errors**  
   â†’ Use lmstudio-community repos (no auth)

---

## ğŸ“š Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Detailed setup guide
- **[CHANGELOG.md](CHANGELOG.md)** - Version history
- **[docs/architecture.md](docs/architecture.md)** - System design
- **[docs/model-comparison.md](docs/model-comparison.md)** - Model selection rationale
- **[docs/development-guide.md](docs/development-guide.md)** - Implementation plan

---

## ğŸ”‘ Key Technical Decisions

| Decision | Rationale |
|----------|-----------|
| **openai-whisper** over faster-whisper | faster-whisper incompatible with ffmpeg 8.0 |
| **Llama 3.1 8B** over TinyLlama | TinyLlama too weak for structured output |
| **Custom MCP** over official SDK | SDK requires Python 3.10+, system has 3.9 |
| **llama.cpp** over transformers | Better Metal support, lower memory usage |

---

## ğŸ¯ Success Criteria

- [x] **Offline:** All AI runs locally
- [x] **M2 Optimized:** Metal acceleration enabled
- [x] **Agentic:** Multi-agent with MCP protocol
- [x] **Transcription:** Whisper integration working
- [x] **Vision:** Image/video analysis working (YOLOv8 + BLIP-2)
- [x] **Chat Interface:** Natural language queries via gRPC
- [x] **Artifacts:** PDF/PPT generation with session context
- [x] **Backend Tests:** Full test suite verified
- [ ] **Frontend UI:** React + Tauri desktop app
- [ ] **Desktop App:** Final packaging and distribution

---

## ğŸš¦ Getting Help

**Model fails to load?**
```bash
# Check file size (should be ~4.9GB, not bytes)
ls -lh backend/models/*.gguf

# Check file type (should be "data")
file backend/models/*.gguf
```

**Import errors?**
```bash
cd backend
source venv/bin/activate
pip list | grep -E "llama|whisper|torch"
```

**GPU not working?**
```bash
python -c "import torch; print(f'MPS: {torch.backends.mps.is_available()}')"
# Should output: MPS: True
```

**Orchestrator test fails?**
```bash
# Ensure venv is activated
cd backend/tests
source ../venv/bin/activate

# Test with intent analysis only (no video needed)
python test_orchestrator.py --intent-only

# Check if model is loaded correctly
ls -lh ../models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
```

---

## ğŸ“ License & Credits

**For:** Intel Senior GenAI Software Solutions Engineer Application  
**Date:** January 2026  
**Tech Stack:** Python, React, Tauri, llama.cpp, Whisper, PyTorch  
**Platform:** macOS (M2 optimized)

---

## ğŸ”„ Recent Updates (Jan 9, 2026)

### Backend Reorganization & Testing
- âœ… Reorganized backend structure:
  - Generated proto files moved to `backend/generated/`
  - Server logs moved to `backend/logs/`
  - All model weights in `backend/models/`
  - Removed duplicate model files
- âœ… Updated all imports and dependencies
- âœ… Fixed PDF report generation (now saves to `tests/results/`)
- âœ… Full backend test suite verified
- âœ… gRPC service tested and operational
- âœ… Documentation updated (README, CHANGELOG, AI-CONTEXT, /docs)

**Current Status:** Backend complete and tested - Ready for frontend development 
